# ğŸš¢ Titanic - Classification de survie

## ğŸ¯ Objectif
Ce projet vise Ã  prÃ©dire la probabilitÃ© de survie des passagers du Titanic en utilisant le jeu de donnÃ©es de la cÃ©lÃ¨bre compÃ©tition Kaggle ["Titanic: Machine Learning from Disaster"](https://www.kaggle.com/c/titanic).  
Lâ€™objectif est de mettre en Å“uvre un pipeline de machine learning complet, depuis lâ€™exploration des donnÃ©es jusquâ€™Ã  lâ€™optimisation dâ€™un modÃ¨le prÃ©dictif.

---

## Data
Le dataset contient les informations des passagers du Titanic, avec notamment :
- **Pclass** : classe du billet (1, 2, 3)
- **Sex** : sexe
- **Age** : Ã¢ge
- **SibSp** : nombre de frÃ¨res/sÅ“urs ou conjoints Ã  bord
- **Parch** : nombre de parents/enfants Ã  bord
- **Fare** : prix du billet
- **Embarked** : port dâ€™embarquement (C, Q, S)
- **Survived** : variable cible (0 = non survÃ©cu, 1 = survÃ©cu)

---

## Ã‰tapes du projet

### 1. Analyse exploratoire (EDA)
- Inspection des donnÃ©es et gestion des valeurs manquantes.  
- Mise en Ã©vidence de corrÃ©lations fortes (via des graphiques, calcule de correlation, test statistiques) :
  - Les femmes survivent beaucoup plus souvent que les hommes.  
  - La classe (Pclass) est un facteur dÃ©terminant.  
  - Les enfants et les passagers avec des billets plus chers (Fare) ont de meilleures chances.  

### 2. PrÃ©processing & Pipeline
- **Imputation** des valeurs manquantes pour toutes les variables (mÃ©diane pour 'Age', mode pour 'Embarked').  
- **Encodage** des variables catÃ©gorielles ('Sex', 'Embarked').  
- **Mise Ã  lâ€™Ã©chelle** des variables numÃ©riques ('Age', 'Fare').  
- **Transformation log1p** appliquÃ©e sur `Fare` pour rÃ©duire lâ€™asymÃ©trie.  
- Construction dâ€™un pipeline sklearn reproductible.  

### 3. ModÃ©lisation
Plusieurs modÃ¨les de classification testÃ©s avec la cross_validation Ã  partir du train set:
- RÃ©gression Logistique  
- Arbre de DÃ©cision  
- Random Forest  
- SVM  

Les performances ont Ã©tÃ© Ã©valuÃ©es via **Accuracy, PrÃ©cision, Rappel et AUC**.
| model               |   accuracy |   precision |   recall |   auc |
|:--------------------|-----------:|------------:|---------:|------:|
| Logistic Regression |      0.8   |       0.765 |    0.693 | 0.853 |
| Decision Tree       |      0.826 |       0.865 |    0.649 | 0.866 |
| Random Forest       |      0.826 |       0.87  |    0.643 | 0.867 |
| SVM                 |      0.823 |       0.803 |    0.713 | 0.838 |

![benchmark_model](reports/roc_curves_of_benchmarked_models.jpg)

- Random Forest et SVM ressortent comme modÃ¨les compÃ©titifs. Le premier obtient la meilleure accuracy (mÃ©trique kaggle) et le second la meilleure prÃ©cision (mÃ©trique critique). 

### 4. Optimisation des hyperparamÃ¨tres
- HyperparamÃ¨tres ajustÃ©s via 'RandomizedSearchCV'.  
- Avec une simple optimisation, le random_forest obtient un recall de 72%. Ce qui est bien mieux que le rÃ©sultats prÃ©cedant. 
- Quant au SVM, les Ã©tapes de fine tuning nous ont permis d'obtenir un recall de 76% en cross_validation. Et comme c'est la mÃ©trique que l'on cherche optimiser. C'est ce modÃ¨le qu'on retiendra pour l'Ã©valuation finale. 

### 5. Ã‰valuation finale
- Accuracy : **~82%**   
- Rappel : **~95%**  
- Courbes ROC et Precision-Recall analysÃ©es pour interprÃ©ter les compromis.  
- DÃ©cision mÃ©tier : privilÃ©gier le **rappel** afin de maximiser lâ€™identification des survivants.  
![precision_recall_curves_of_the_final_model](reports/Precision-and-recall-curves-of-the-final-model.jpg)
NB: Le datasets Ã©tant de petite taille il y a une variabilitÃ© des rÃ©sultats du modÃ¨le, ce qui peut expliquer les meilleurs rÃ©sultats sur le test set plutÃ´t que le train set. De plus, j'utilise les datasets de train et test prÃ©parÃ©s par kaggle et il se peut qu'il y ait une certaine variablitÃ©. 
---

## âœ… RÃ©sultats
- Le modÃ¨le final atteint **91% dâ€™accuracy** sur lâ€™Ã©chantillon de test.  
- Il offre un **rappel de 95%**, ce qui est crucial dans un contexte oÃ¹ il vaut mieux prÃ©dire un maximum de survivants, quitte Ã  avoir des faux positifs.  
- Le projet illustre un **workflow ML complet** :  
  > EDA â†’ Pipeline sklearn â†’ ModÃ©lisation â†’ Tuning â†’ Ã‰valuation finale.  

---
## Conclusion

Ce projet visait Ã  prÃ©dire la survie des passagers du Titanic Ã  partir des donnÃ©es Kaggle.  
AprÃ¨s une analyse exploratoire mettant en Ã©vidence lâ€™impact majeur du sexe, de la classe et de lâ€™Ã¢ge sur la survie, nous avons construit un pipeline de transformation intÃ©grant lâ€™imputation des valeurs manquantes, la standardisation des variables numÃ©riques et lâ€™encodage des variables catÃ©gorielles.  

Plusieurs modÃ¨les de classification ont Ã©tÃ© testÃ©s (rÃ©gression logistique, arbre de dÃ©cision, random forest, SVM).  
Leur performance a Ã©tÃ© comparÃ©e Ã  lâ€™aide de mÃ©triques telles que lâ€™accuracy, la prÃ©cision, le rappel et lâ€™AUC.  
Le modÃ¨le final retenu, aprÃ¨s optimisation des hyperparamÃ¨tres, atteint une accuracy de ~82% et un rappel de ~71% sur lâ€™Ã©chantillon de test.  

En pratique Kaggle, lâ€™accuracy est la mÃ©trique officielle, mais dans un contexte mÃ©tier rÃ©el (sauver des vies), le recall est la mÃ©trique phare afin de maximiser la dÃ©tection des survivants.  
Ce projet illustre ainsi la mise en Å“uvre dâ€™un workflow complet de machine learning : de lâ€™EDA au pipeline sklearn, jusquâ€™au tuning dâ€™hyperparamÃ¨tres et Ã  lâ€™Ã©valuation finale du modÃ¨le.



